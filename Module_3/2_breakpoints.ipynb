{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import START, END, StateGraph, MessagesState\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.prebuilt import tools_condition, ToolNode\n",
    "from langchain_core.messages import HumanMessage\n",
    "from pprint import pprint\n",
    "\n",
    "def multiply(a, b):\n",
    "    \"\"\"Return the multiplication of two numbers.\"\"\"\n",
    "    return a*b\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "\n",
    "tools = [multiply]\n",
    "\n",
    "tool_calls = llm.bind_tools(tools)\n",
    "\n",
    "class State(MessagesState):\n",
    "    pass\n",
    "\n",
    "def tool_calling_model(state: MessagesState):\n",
    "    return{\"messages\":[tool_calls.invoke(state[\"messages\"])]}\n",
    "\n",
    "builder =  StateGraph(State)\n",
    "\n",
    "builder.add_node(\"tool_calling_model\", tool_calling_model)\n",
    "builder.add_node(\"tools\",ToolNode(tools))\n",
    "\n",
    "builder.add_edge(START, \"tool_calling_model\")\n",
    "builder.add_conditional_edges(\"tool_calling_model\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"tool_calling_model\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(interrupt_before=[\"tool_calling_model\"], checkpointer=memory)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Multiply 3*3' additional_kwargs={} response_metadata={} id='c9ff38dc-7b29-4416-8bc7-898acd171553'\n",
      "content='' additional_kwargs={'tool_calls': [{'id': 'call_nHjWO3nsV5M4gxUcRJYp6puN', 'function': {'arguments': '{\"a\":3,\"b\":3}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None} response_metadata={'token_usage': {'completion_tokens': 18, 'prompt_tokens': 61, 'total_tokens': 79, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_bd83329f63', 'finish_reason': 'tool_calls', 'logprobs': None} id='run-4bbd17c6-db6a-4edd-a240-551c9596c7cd-0' tool_calls=[{'name': 'multiply', 'args': {'a': 3, 'b': 3}, 'id': 'call_nHjWO3nsV5M4gxUcRJYp6puN', 'type': 'tool_call'}] usage_metadata={'input_tokens': 61, 'output_tokens': 18, 'total_tokens': 79, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_nHjWO3nsV5M4gxUcRJYp6puN)\n",
      " Call ID: call_nHjWO3nsV5M4gxUcRJYp6puN\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 3\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "9\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying 3 by 3 is 9.\n"
     ]
    }
   ],
   "source": [
    "# User Approval\n",
    "input_message = {\"messages\": HumanMessage(content=\"Multiply 3*3\")}\n",
    "thread = {\"configurable\":{\"thread_id\": \"2\"}}\n",
    "for event in graph.stream(input_message, thread, stream_mode=\"values\"):\n",
    "    print(event[\"messages\"][-1])\n",
    "state  = graph.get_state(thread)\n",
    "state.next\n",
    "user_approval = input(\"Do you want to continue? (yes/no) \")\n",
    "if user_approval== \"yes\":\n",
    "    for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "        event[\"messages\"][-1].pretty_print()\n",
    "else:\n",
    "    print(\"Operation Failed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '2',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1efe94ce-5a6a-6cb6-8001-9c8c716d9cb6'}}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {\"messages\": HumanMessage(content=\"Multiply 3*3\")}\n",
    "thread = {\"configurable\":{\"thread_id\": \"2\"}}\n",
    "for event in graph.stream(query, thread, stream_mode=\"values\"):\n",
    "    print(event[\"messages\"][-1])\n",
    "# Editing State Fraph before the Assistant for updating the query\n",
    "graph.update_state(\n",
    "    thread,\n",
    "    {\"messages\": HumanMessage(content=\"No multiply 3*4\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "No multiply 3*4\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  multiply (call_CGPWT48tWn4qBQxoWkC0Fgrr)\n",
      " Call ID: call_CGPWT48tWn4qBQxoWkC0Fgrr\n",
      "  Args:\n",
      "    a: 3\n",
      "    b: 4\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: multiply\n",
      "\n",
      "12\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The result of multiplying \\(3 \\times 4\\) is \\(12\\).\n"
     ]
    }
   ],
   "source": [
    "for event in graph.stream(None, thread, stream_mode=\"values\"):\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
